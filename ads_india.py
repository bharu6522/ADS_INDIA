# -*- coding: utf-8 -*-
"""ADS_INDIA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uTtGfpnl5edNg9C9pUlNhoM5EL7UazXO
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

test = pd.read_csv("/content/test.csv")
train = pd.read_csv("/content/train.csv")

print(train.shape)
print(test.shape)
print(train.head(5))
print(train.columns)
print(test.columns)
print(train.info())
print(test.info())

train.isnull().sum()

train.dropna(inplace=True)

test.isnull().sum()

test.dropna(inplace= True)

# plotting class distribution
sns.countplot(x='CLASS',data = test)
plt.title("Class distribution")
plt.show()

train['length'] = train['CONTENT'].apply(len)

#plotting distribution of content length
plt.figure(figsize=(6,4))
sns.histplot(train['CONTENT'],bins=50, kde = True)
plt.title('Distribution of Comment Lengths')
plt.xlabel('Comment Length')
plt.ylabel('Frequency')
plt.show()

all_comments = ' '.join(train['CONTENT'])

from wordcloud import WordCloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_comments)

# Display the word cloud
plt.figure(figsize=(10, 6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud of All Comments')
plt.show()

import nltk
# Download stopwords
nltk.download('stopwords')
nltk.download('punkt')

from collections import Counter
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
stop_words = set(stopwords.words('english'))

# Tokenize the comments and remove stopwords
train['tokens'] = train['CONTENT'].apply(lambda x: [word for word in word_tokenize(x.lower()) if word.isalnum() and word not in stop_words])

# Flatten the list of tokens
all_tokens = [token for sublist in train['tokens'] for token in sublist]

# Get the most common words
common_words = Counter(all_tokens).most_common(20)

# Plot the most common words
common_words_df = pd.DataFrame(common_words, columns=['word', 'count'])
plt.figure(figsize=(10, 6))
sns.barplot(x='count', y='word', data=common_words_df)
plt.title('Most Common Words')
plt.xlabel('Count')
plt.ylabel('Word')
plt.show()

from nltk.util import ngrams

# Function to get n-grams
def get_ngrams(tokens, n):
    n_grams = ngrams(tokens, n)
    return [' '.join(grams) for grams in n_grams]

# Get bigrams and trigrams
train['bigrams'] = train['tokens'].apply(lambda x: get_ngrams(x, 2))
train['trigrams'] = train['tokens'].apply(lambda x: get_ngrams(x, 3))

# Flatten the lists of bigrams and trigrams
all_bigrams = [bigram for sublist in train['bigrams'] for bigram in sublist]
all_trigrams = [trigram for sublist in train['trigrams'] for trigram in sublist]

# Get the most common bigrams and trigrams
common_bigrams = Counter(all_bigrams).most_common(20)
common_trigrams = Counter(all_trigrams).most_common(20)

# Plot the most common bigrams
common_bigrams_df = pd.DataFrame(common_bigrams, columns=['bigram', 'count'])
plt.figure(figsize=(10, 6))
sns.barplot(x='count', y='bigram', data=common_bigrams_df)
plt.title('Most Common Bigrams')
plt.xlabel('Count')
plt.ylabel('Bigram')
plt.show()

# Plot the most common trigrams
common_trigrams_df = pd.DataFrame(common_trigrams, columns=['trigram', 'count'])
plt.figure(figsize=(10, 6))
sns.barplot(x='count', y='trigram', data=common_trigrams_df)
plt.title('Most Common Trigrams')
plt.xlabel('Count')
plt.ylabel('Trigram')
plt.show()

test_comment = test['CONTENT']
train_comment = train['CONTENT']
test_class = test['CLASS']

all_comments = pd.concat([train_comment, test_comment])

all_comments.isnull().sum()

from sklearn.feature_extraction.text import TfidfVectorizer
vector = TfidfVectorizer(max_features=1000)
all_feature = vector.fit_transform(all_comments).toarray()

x_train = all_feature[:len(train_comment)]
x_test = all_feature[len(train_comment):]
# Create a label array with -1 for unlabeled training data and actual labels for test data
y_train = [-1] * len(train_comment)
y_test = test_class.values
all_labels = np.concatenate([y_train, y_test])

from sklearn.semi_supervised import LabelSpreading
from sklearn.ensemble import RandomForestClassifier

label_spread = LabelSpreading(kernel='knn', n_neighbors=5, alpha=0.8)
label_spread.fit(all_feature, all_labels)
y_train_pred = label_spread.transduction_[:len(train_comment)]
classifier = RandomForestClassifier(n_estimators=100, random_state=42)
classifier.fit(x_train,y_train_pred)
y_pred = classifier.predict(x_test)

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(f'Accuracy: {accuracy_score(y_test, y_pred)}')

conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt='d')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

"""USING DECISION TREE"""

from sklearn.tree import DecisionTreeClassifier
classifier2 = DecisionTreeClassifier(random_state=42)
classifier2.fit(x_train,y_train_pred)
y_pred = classifier2.predict(x_test)
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(f'Accuracy: {accuracy_score(y_test, y_pred)}')
# Visualize the results
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt='d')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

"""USING SVM"""

from sklearn.svm import SVC
classifier3 = SVC(kernel='linear', random_state=42)
classifier3.fit(x_train,y_train_pred)
y_pred = classifier3.predict(x_test)
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(f'Accuracy: {accuracy_score(y_test, y_pred)}')

# Visualize the results
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt='d')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

"""USING ENSEMBLE METHOD"""

from sklearn.linear_model import LogisticRegression
log_clf = LogisticRegression(random_state=42)
dt_clf = DecisionTreeClassifier(random_state=42)
svm_clf = SVC(kernel='linear', random_state=42)
from sklearn.ensemble import VotingClassifier
voting_clf = VotingClassifier(
    estimators=[('lr', log_clf), ('dt', dt_clf), ('svm', svm_clf)],
    voting='hard'
)
voting_clf.fit(x_train, y_train_pred)

# Make predictions on the test set
y_pred = voting_clf.predict(x_test)

# Evaluate the model
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(f'Accuracy: {accuracy_score(y_test, y_pred)}')

# Visualize the results
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt='d')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()